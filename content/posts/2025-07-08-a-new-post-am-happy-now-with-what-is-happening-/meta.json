{
  "Id": "3549fbeb-7a0e-4614-8097-b1e563ce8e55",
  "Title": "a new post am happy now with what is happening ",
  "Description": "this post is a dummy one just a trial ",
  "Slug": "a-new-post-am-happy-now-with-what-is-happening-",
  "Content": "A month ago I set out to build a free open-source PDF chat app. I honestly expected it to be super easy.\r\n\r\nUpload a PDF, extract the text, feed it to an LLM. What could go wrong?\r\n\r\nAs it turned out, PDF parsing proved extremely annoying. I tried PyMuPDF, Unstructured, Chunkr, and every other PDF parsing library I could find. They were either painfully slow, prohibitively expensive, or produced garbage output. Server-side processing meant users waited 20\u002B seconds watching a spinner. Adding PDF processing to my backend added a lot of complexity. Worst of all, as a user, I didn\u2019t love the experience.\r\n\r\nI wrote an article about my journey building pdfgpt.co, but have since come up with a better solution: a little known library called @opendocsg/pdf2md.\r\n\r\nThe Enterprise PDF Processing Disaster Nobody Talks About\r\nWhile debugging my app, I started talking to enterprise engineering teams about their PDF processing. The scale they were working at genuinely surprised me. One consumer chat app with millions of active users processes tens of millions of PDF pages a month. For another it\u2019s in the range of hundreds of millions of pages.\r\n\r\nThe infrastructure always looks the same: a microservice with PyMuPDF or similar library that\u2019s constantly needing maintenance, and costs tens of thousands per month. As the microservice grows, it needs load balancers for traffic distribution, queue systems for spikes, and a DevOps constantly handling fires.\r\n\r\nWhen you account for time wasted, the cost easily expands to hundreds of thousands per year, just for processing PDFs at a large scale.\r\n\r\nAnd it all starts from some innocuous code like this:\r\n\r\n# Upload large pdf file to server (network latency)\r\npdf_content = await file.read()\r\n# Process on server (extremely CPU intensive)\r\nmarkdown = extract_text_from_pdf(pdf_content)\r\n# Return result (more network latency)\r\nreturn {\u0022markdown\u0022: markdown}\r\nMy solution looked a lot like the above \u2014 the exact pdf parsing lib isn\u2019t as important as the fact that my best-case pdf processing time was still several seconds. I didn\u2019t even have a separate microservice for PDF parsing \u2014 the stability of my project was in serious danger at any real scale.\r\n\r\nThen I found @opendocsg/pdf2md \u2014 a JavaScript library that runs entirely in the browser. No servers. No uploads. No infrastructure.\r\n\r\nThe Solution: Let the Browser Do the Work\r\nHere\u2019s the beautiful thing about modern browsers \u2014 they\u2019re incredibly powerful. We\u2019re talking about runtime environments that can handle 3D graphics, compile WebAssembly, and process gigabytes of data. So why are we uploading PDFs to servers for basic text extraction? With @opendocsg/pdf2md, the entire process happens client-side:",
  "CreatedAt": "2025-07-08T12:18:57.6005197Z",
  "UpdatedAt": null,
  "ScheduledAt": null,
  "ReadingTime": "2 min read",
  "LikeCount": 0,
  "LikedByUserIds": [],
  "Comments": [],
  "Status": 1,
  "Tags": [
    "minimal-api",
    "web-development"
  ],
  "Categories": [
    "Development"
  ],
  "IsPublished": true
}